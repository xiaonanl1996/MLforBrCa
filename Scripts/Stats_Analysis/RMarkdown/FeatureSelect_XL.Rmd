---
title: "Initial Exploration of MLforBrCa"
author: "Xiaonan Liu"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: show
    highlight: kate
---

```{r setup, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(include=TRUE, echo=FALSE)

library(kableExtra)
library(knitr)
library(yaml)
library(here)
library(ggplot2)
library(tidyr)
library(DiagrammeR)
library(DiagrammeRsvg)
library(magrittr)
library(svglite)
library(rsvg)
library(png)
library(grid)
library(dplyr)
library(survival)
library(survminer)
library(naniar)
library(summarytools)
library(rsample)      # data splitting 
library(gbm)          # basic implementation
library(xgboost)      # a faster implementation of gbm
library(caret)        # an aggregator package for performing many machine learning models
library(h2o)          # a java-based platform
library(pdp)          # model visualization
library(lime)         # model visualization
library(vip)          # Feature importance visualisation

# Specify the markdown format for knitr tables, otherwise they're not compatible with kableExtra
options(knitr.kable.NA='', knitr.table.format = "html")
options(kableExtra.auto_format = FALSE)
options(rstudio.connectionObserver.errorsSuppressed = TRUE)
# Set the root directory to the project directory (otherwise knitr works in the directory of the Rmd file by default)
knitr::opts_knit$set(root.dir = here::here())

# Load the project config file for filepaths etc
config = yaml.load_file(here::here("./config.yml"))
source(here::here(config$functions$general))

#-------------------------------------------------------------------------------------------------------------------
# Setup

figure <- 1
table <- 1
suppfig <- 1
footnote_no <- 1

load(here::here(file.path(config$data$derived,"gbm.RData")))

tot_train<-readRDS(here::here(file.path(config$data$derived,"tot_train.rds")))
tot_test<-readRDS(here::here(file.path(config$data$derived,"tot_test.rds")))
```

# Introduction

This report outlines the steps and results of exploration of MLforBrCa. We searched from 910 UKB fields using gradient boosting trees (GBM) and see which ones are associated with Breast Cancer outcome.


# Input Features

Searching scope includes **910 variables from Core dataset by UKB**.

It covers from socio-demographics, lifestyle (alcohol, physical activity...), family history, prevalent health conditions (top level ICD10), medications, blood biochemsitry (LDL, HDL,â€¦), BP. For more details, please visit **Table 1 "Input features-20210906" in MLforBrCa_Log.docx under Section 6.2**.

# Outcome & Exclusions

Breast cancer cases were defined based on ICD-9 code (174\*) and ICD-10 code (C50\*) from cancer registry (CaR) supplemented with HES (beyond last available CaR).

Follow-up time for each participant was computed as the number of years from baseline until the earliest of the following: 

* BrCa event date
* Non BrCa death date (All ICD-10 code except C50\*)
* Incident Mastectomy (OPCS-4 code: B27\*, B28\*(except B28.5, B28.7, B28.8, B28.9), B41\*)
* Lost to follow-up date
* UKB Admin censoring date (England: 28Feb2021 Wales: 28Feb2018 Scotland: 28Feb2021)

Exclusion criteria were shown in the analysis population flowchart below.

```{r derive-data, include=FALSE, cache=TRUE}
source(file.path(config$scripts$cleaning, "dataset_generator.R"))


pretty_func <- pretty_switch(field_definitions=c(TEU_SPECS$BrCa_PRS,TEU_SPECS$BrCa_PRS_v2.2), return_type = "function")
pretty_names <- pretty_switch(field_definitions=c(TEU_SPECS$BrCa_PRS,TEU_SPECS$BrCa_PRS_v2.2), return_type="list")

```


```{r,fig.height=10}
img<-readPNG(file.path(config$outputs$descriptives, "BrCa_excl.png"))
grid.raster(img,width=0.8,height=1)

```

## Input features

After applying exclusion criteria, dataset was divided to **training (56%), validation (14%) and test (30%, N=`r nrow(tot_test)`) sets**. 

After derivation, there were initially `r ncol(tot_train%>%select(!c(ID,TEU_BrCa_status,TEU_BrCa_time)))` input features. `r tot_train%>%select(contains(c("HES","CaR")))%>%names%>%length` of them are actually conditions identified from hospital inpatient (HES) or Cancer Registry (CaR) using level 2 ICD-10 code.

**Missing Data**: Below is the missingness of features: 

```{r}

miss_sum<-tot_train%>%miss_var_summary()%>%
  filter(n_miss!=0)%>%
  rowwise()%>%
  mutate(variable=pretty_func(variable))%>%
  rename(Variable=variable,`Number of missing values`=n_miss,`Missing perc (%)`=pct_miss)

kable(miss_sum)%>%
  kable_styling(bootstrap_options = c("striped", "hover"))%>%
  scroll_box(width = "100%", height = "1000px")

# Remove vars with >30% missing
remove_vars<-tot_train%>%miss_var_summary()%>%filter(pct_miss>30)%>%pull(variable)

tot_train<-tot_train%>%select(!all_of(remove_vars))
  

```

We removed `r length(remove_vars)` features with missing percentage > 30%, which lead to total of `r ncol(tot_train%>%select(!c(ID,TEU_BrCa_status,TEU_BrCa_time)))` input features.


<span style="color: red;"> Note that established RF, age at menopause, age at first birth and age at last birth all have missingness > 30%, therefore are not part of the input features. </span>

Due to the limitation of `gbm` package in R that it can only handles up to 1024 factor levels.We'd have to remove more features. Instead of choosing first 1k features, I looked at the HES/CaR conditions and removed the rare conditions (i.e. <20 people had the condition)

```{r sparse}

# Freq of HES
freq_HES<-as.data.frame(tot_train%>%select(contains("TEU_HES"))%>%mutate_all(~as.numeric(.)-1)%>%colSums)%>%
  `colnames<-`(c("Freq"))

sparse_HES<-freq_HES%>%filter(Freq<20)%>%rownames

# Freq of CaR
freq_CaR<-as.data.frame(tot_train%>%select(contains("CaR"))%>%colSums)%>%
  `colnames<-`(c("Freq"))

sparse_CaR<-freq_CaR%>%filter(Freq<20)%>%rownames


# Remove sparse features from tot_train

tot_train<-tot_train%>%
  select(!all_of(c(sparse_CaR,sparse_HES)))

#saveRDS(tot_train,file=file.path(config$data$derived,"tot_train_after.RDS"))

```

We removed `r length(c(sparse_CaR,sparse_HES))` rare HES/CaR conditions, which lead to **total of `r ncol(tot_train%>%select(!c(ID,TEU_BrCa_status,TEU_BrCa_time)))` input features**.


# Descriptive Stats

Descriptive statistics of **training+validation set** is stored under 'K:\\TEU\\MLforBrCa\\Stats_Outputs\\Descriptives\\DescrpStats_train.html'.

```{r Descriptive stats,cache=TRUE}

# Pretty variable names
pretty_colnames<-sapply(names(tot_train), function(i) pretty_func(i))

tmp<-tot_train;names(tmp)<-pretty_colnames

#p<-dfSummary(tmp);view(p)

print(dfSummary(tmp,
                valid.col = FALSE,
                #headings=FALSE,
                max.string.width=406),
      caption='Descriptive characteristics of training data (MLforBrCa)',
      file = file.path(config$outputs$descriptives,'DescrpStats_train.html'))

```


According to this [StackOverflow](https://stackoverflow.com/questions/14718648/r-gbm-handling-of-missing-values), `gbm` r package handles missing data by assigning them a different node XL thinking: As a first thought, it still seems a bit alarming to me if we are using features with really extreme high missing percentage to me because this missing information would be affect the model structure.

**Sparse Data**: In our data we have some sparse variables, e.g. rare conditions or rare medications. So far it doesn't cause any errors or warnings for model fitting so I guess it's okay? People mentioned XGBoost works great for sparse data but I'm not so sure if GBM works great with sparse data.


# GBM in R

Here I'm using R package, `gbm` to implement GBM. Since we have survival outcomes, I used **coxph deviance (i.e. -2$\times$log partial likelihood) as the loss function**.

General note: Some of my implementation notes were kept in Section 8.1.2 in MLforBrCa project log. Perhaps I should reorganise them into the Html guide at some point.

## Hyper-parameter tuning

For GBM, there are 2 sets of hyper-parameters to tune: **Boosting hyperparameters** and **tree-specific hyperparameters**.

Unlike random forests, GBMs can have high variability in accuracy dependent on their hyperparameter settings [(Probst, Bischl, and Boulesteix 2018)](https://arxiv.org/abs/1802.09596). So tuning can require much more strategy than a random forest model. The strategy I followed below were based on [Analyticvidhya](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/). I think the main idea is 

1. First choose a relative high learning rate (`shrinkage`), e.g. 0.1. 
2. Determine the optimal number of trees (`n.trees`) for this learning rate because they are highly interconnected.
3. Tune tree-specific parameters. 
4. Lowering learning rate and increase number of trees accordingly to get more robust model.

I think the logic behind this order is that we would like to first decide the rough structure of GBM (hence first tune high level hyperparameters such as learning rate and number of trees). Then once the structure is set, we tune the specific tree hyperparameters. The main reason we start with a relative high learning rate is based from the trade-off between predictive performance and computation costs. According to [gbm vignette](https://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf), it says

_"It is important to know that smaller values of shrinkage (almost) always give improved predictive performance. That is, setting shrinkage=0.001 will almost certainly result in a model with better out-of-sample predictive performance than setting shrinkage=0.01. However, there are computational costs, both storage and CPU time, associated with setting shrinkage to be low."_

### My Action

Step 1: Create the baseline GBM model with the following parameter values: 

* Learning rate (`shrinkage`=0.1): According to [Hands on ML in R Chp 12](https://bradleyboehmke.github.io/HOML/gbm.html), generally the default value of 0.1 works but somehow between 0.05-0.2 should work across a wide range of problems. So as a starting point, I just chose 0.1.

* Number of trees (`n.trees`=1000): I set a large number, we can see the optimal number of trees later.

* Maximum depth of trees (`interaction.dpeth`=3): More commonly, depth is greater than 1 but it is unlikely to have depth greater than 10 because the way GBM works (This is one of the differences from random forest). This is randomly set, will tune later.

* Minimum number of observation in terminal node (i.e. leaf) (`n.minobsinnode`=10): This is the default value, will tune later.

* Fraction of observations to be selected for each tree (`bag.fraction`=0.5): This is the default value, recommend by [gbm vignette](https://cran.r-project.org/web/packages/gbm/vignettes/gbm.pdf).

Step 2: Determine the optimal number of trees by plotting loss function against number of trees added to the ensemble. The loss values were computed as the loss from validation set.

```{r baseline gbm model,eval=FALSE}
# Copied from BMRC

# for reproducibility
set.seed(123)

# train baseline GBM model
gbm.fit <- gbm(
  formula = Surv(TEU_BrCa_time, TEU_BrCa_status) ~ .-ID,
  distribution = "coxph",
  data = tot_train,
  n.trees = 1000,
  interaction.depth = 3,
  n.minobsinnode = 10, #min number of obs in leaf (i.e. terminal node)
  shrinkage = 0.1,
  bag.fraction = 0.5,
  train.fraction = 0.8,
  #cv.folds = 5,
  verbose = TRUE
)  

```

```{r}

# plot loss function as a result of n trees added to the ensemble (See optimal # of trees )
gbm.perf(gbm.fit, method = "test")
# Line in black plots train.error; line in red plots validation.error 

# find index for number trees with minimum validation error
best <- which.min(gbm.fit$valid.error)

best.error<-gbm.fit$valid.error[best]

# Try concordance index on validation data (There's no valid.fitted from gbm.fit)
first_valid<-round(nrow(tot_train)*gbm.fit$train.fraction)+1
tot_valid<-tot_train[first_valid:nrow(tot_train),]

pred.valid <- predict(gbm.fit, tot_valid, n.trees = best)

best.cindex<-survConcordance(Surv(TEU_BrCa_time, TEU_BrCa_status) ~ pred.valid,data=tot_valid)
```

From the plot above, y-axis is coxph loss, x-axis 'Interaction' stands for number of trees (`n.trees`).Black line represents the training loss whereas red line indicates validation loss. Blue dotted line shows where the lowest point of validation loss is, which is at `r pretty_dp(best,2)` trees. The corresponding validation loss is `r best.error`; because there's no standard threshold to tell if this value is low enough, I also presented the Harrell's C-index computed on validation predicted values on the scale of linear predictor, which is `r pretty_dp(best.cindex$concordance,2)`. 


Step 3: Using the intial choice of learning rate and corresponding number of trees, we tune tree-specific parameters by grid search. 

```{r hyper-parameter tuning, echo=TRUE, eval=FALSE}
# Copied from BMRC

# Grid search for tree-specific

hyper_grid <- expand.grid(
  interaction.depth = c(1, 3, 5),
  n.minobsinnode = c(5, 10, 15, 20),
  optimal_trees = 0,     # a place to dump results
  min_coxph = 0   # a place to dump results
  #max_concord = 0,   # a place to dump results
)


# grid search 
for(i in 1:nrow(hyper_grid)) {
  
  # reproducibility
  set.seed(123)
  
  # Add computation time 
  start_time <- Sys.time()
  
  cat("Grid search ",i," starting at ",as.character(start_time),"\n")
  
  # train model
  gbm.tune <- gbm(
    formula = Surv(TEU_BrCa_time, TEU_BrCa_status) ~ .-ID,
    distribution = "coxph",
    data = tot_train,
    n.trees = 600, 
    interaction.depth = hyper_grid$interaction.depth[i],
    shrinkage = 0.1,
    n.minobsinnode = hyper_grid$n.minobsinnode[i],
    train.fraction = 0.8,
    #cv.folds = 5,
    #n.cores = NULL, # will use all cores by default
    verbose = FALSE
  )
  
  end_time <- Sys.time()
  
  #concord <- survConcordance(Surv(TEU_BrCa_time, TEU_BrCa_status) ~ gbm.tune$cv.fitted,data=tot_train)
  
  # add min training error and trees to grid
  # Note: Even though the n.trees were fixed as 200, it can still search for the optimal trees (<200)
  hyper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)
  hyper_grid$min_coxph[i] <- min(gbm.tune$valid.error)
  
  cat("Grid search ",i," done! Time spent: ",round(end_time-start_time,1),"\n")
  
}

```

We assessed `r nrow(hyper_grid)` combinations of hyper-parameters where `interaction.depth` choosing from `r unique(hyper_grid$interaction.depth)` and `n.minobsinnode` choosing from `r unique(hyper_grid$n.minobsinnode)`. The optimal model was currently chosen based on loss function, not Harrell's C index.

```{r}

optimal_combo<-hyper_grid%>%arrange(min_coxph)

optimal_combo%>%rename(`coxph loss`=min_coxph)

```

Based on the cv loss of each combination of parameters, the optimal tree specific parameters are`interaction.depth`=`r optimal_combo$interaction.depth[1]`, `n.minobsinnode`=`r optimal_combo$n.minobsinnode[1]`, `bag.fraction`=0.5. 

Step 4: Lower learning rate (i.e. shrinkage) and perform more stringent hyper-parameter tuning.

```{r More hyper-parameter tuning,eval=FALSE}
# Copied from BMRC

# Grid search for shrinkage

hyper_grid2 <- expand.grid(
  shrinkage = c(0.01,0.05,0.1),
  n.trees = c(4000,1000,800,400), # need to add
  optimal_trees = 0,     # a place to dump results
  min_coxph = 0   # a place to dump results
  #max_concord = 0,   # a place to dump results
)

# total number of combinations
nrow(hyper_grid2) 

# grid search 
for(i in 1:nrow(hyper_grid2)) {
  
  # reproducibility
  set.seed(123)
  
  # Add computation time 
  start_time <- Sys.time()
  
  cat("Grid search ",i," starting at ",as.character(start_time),"\n")
  
  # train model
  gbm.tune <- gbm(
    formula = Surv(TEU_BrCa_time, TEU_BrCa_status) ~ .-ID,
    distribution = "coxph",
    data = tot_train,
    n.trees = hyper_grid2$n.trees[i], 
    interaction.depth = 1, 
    shrinkage = hyper_grid2$shrinkage[i],
    n.minobsinnode = 20, 
    bag.fraction = 0.5, # default
    train.fraction = 0.8,
    #cv.folds = 5,
    verbose = FALSE
  )
  
  end_time <- Sys.time()
  
  #concord <- survConcordance(Surv(TEU_BrCa_time, TEU_BrCa_status) ~ gbm.tune$cv.fitted,data=tot_train)
  
  # add min training error and trees to grid
  hyper_grid2$optimal_trees[i] <- which.min(gbm.tune$valid.error)
  hyper_grid2$min_coxph[i] <- min(gbm.tune$valid.error)
  
  cat("Grid search ",i," done! Time spent: ",round(end_time-start_time,1),"\n")

}

```

We assessed `r nrow(hyper_grid2)` combinations of hyper-parameters where `shrinkage` choosing from `r unique(hyper_grid2$shrinkage)` and `n.trees` choosing from `r unique(hyper_grid2$n.trees)`. The optimal model was currently chosen based on loss function, not Harrell's C index.

```{r}

optimal_combo2<- hyper_grid2%>%arrange(min_coxph)

optimal_combo2%>%rename(`coxph loss`=min_coxph)

```

Based on the cv loss of each combination of parameters, **the optimal parameters are`interaction.depth`=`r optimal_combo$interaction.depth[1]`, `n.minobsinnode`=`r optimal_combo$n.minobsinnode[1]`, `bag.fraction`=0.5, `shrinkage`=`r optimal_combo2$shrinkage[1]` and `n.trees`=`r optimal_combo2$optimal_trees[1]`**. 


Step 5: Fit optimal model and perform feature importance.

```{r optimal model fitting,eval=FALSE}
# Copied from BMRC

# Optimal model 

# find set of parameters with minimum CV error
optimal <- which.min(hyper_grid2$min_coxph)

# for reproducibility
set.seed(123)

# train GBM model
gbm.optimal <- gbm(
  formula = Surv(TEU_BrCa_time, TEU_BrCa_status) ~ .-ID,
  distribution = "coxph",
  data = tot_train,
  n.trees = hyper_grid2$optimal_trees[optimal],
  interaction.depth = 1,
  n.minobsinnode = 20, #min number of obs in leaf (i.e. terminal node)
  shrinkage = hyper_grid2$shrinkage[optimal],
  bag.fraction = 0.5,
  train.fraction = 0.8,
  #cv.folds = 5,
  verbose = TRUE
)  

```

```{r}
# print results
print(gbm.optimal)


# find index for number trees with minimum validation error
optimal <- which.min(gbm.optimal$valid.error)


optimal.error<-gbm.optimal$valid.error[optimal]

# Try concordance index on validation data (There's no valid.fitted from gbm.fit)
pred.valid <- predict(gbm.optimal, tot_valid, n.trees = optimal)

optimal.cindex<-survConcordance(Surv(TEU_BrCa_time, TEU_BrCa_status) ~ pred.valid,data=tot_valid)


```

After training the optimal model, we found the validation loss is `r optimal.error` and **Harrell's C index is `r pretty_dp(optimal.cindex$concordance,2)`**. 

Finally, we could perform feature importance evaluation to see which features are associated with Breast cancer outcome. According to Section 1.11.2.5 from [scikit-learn tutorial](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)):

_The relative rank (i.e. depth) of a feature used as a decision node in a tree can be used to assess the relative importance of that feature with respect to the predictability of the target variable.Features used at the top of the tree contribute to the final prediction decision of a larger fraction of the input samples. The expected fraction of the samples they contribute to can thus be used as an estimate of the relative importance of the features._

[XL]: Here we presented relative influence, which seems like a standard metric people usually report. We could also use permutation importance instead but currently not implemented yet.I still need to read more on this.

Below shows the table of features with non-zero relative influence **computed using training+validation data**. Established RFs (From [CRUK](https://www.cancerresearchuk.org/about-cancer/breast-cancer/risks-causes/risk-factors)) are highlighted in <span style="background-color: yellow">yellow</span>.

<span style="color: red;">Note on variable names: </span>

* G03FA,G03AA,G02BA,G03DC are medication ATC groups that related to birth control. C09DA,C08CA,C03AA are related to treating high BP. G03FB, G03CX are medication group for hormone replacement. A10BG are medication group for type 2 diabetes. M04AA is medication group for treating gout and kidney stones.H03AA is medication group for hypothyroidism. D02AX, S01XA don't seem to have a clear indication to me of their use.

For more information on ATC groups, please visit Section 6.3 in MLforBrCa_Log.docx. For the meaning of ATC group, please visit mapping: 'K:\\TEU\\UKB33952_Data\\Data_Dictionary\\Mappings\\Analysis_codings_xlsx\\Medication\\Wu2019_Sup1.xlsx'

* IGF-1, Alkaline phosphatase, SHBG, Gamma glutamyltransferase,Total protein, Phosphate, Glucose, Oestradiol, Glycated haemoglobin (HbA1c), Urea, C-reactive protein, Apolipoprotein A, Total bilirubin, Aspartate aminotransferase, LDL direct, Albumin, Direct bilirubin, Rheumatoid factor, Cholesterol, HDL, Urate all belong to blood biochemistry category.

* Summed MET is Summed MET minutes per week for all activity (i.e. a physical activity variable).

* Family history of Other cancer includes FaH of Bowel cancer,Prostate cancer,Lung cancer.

```{r Feature Imp,echo=TRUE}

# Feature importance
importance<-summary(
  gbm.optimal, 
  plotit=FALSE,
  #cBars = 40,
  method = relative.influence, # also can use permutation.test.gbm
  las = 2
  )

# produce the table with human readable name
imp_tab<-importance%>%
  filter(rel.inf!=0)%>%
  rename(Variable=var,`Relative Influence`=rel.inf)%>%
  rowwise%>%
  mutate(Variable=pretty_func(Variable))%>%
  # Add line break in 2nd space (' ') of Variable
  mutate(
      Variable = if_else(
        str_count(Variable, '\\S+') > 5,
        str_c(word(Variable,1,4), word(Variable,5,str_count(Variable,'\\S+')), sep = '\n'),
        Variable
      )
    )

kable(imp_tab)%>%
  kable_styling(bootstrap_options = c("striped", "hover"))%>%
  row_spec(c(3:6,9,19:20,40,42,65,67,68,71,91,172,178),background = "yellow")

# Visualise
ggplot(data=imp_tab[1:20,], aes(x=reorder(Variable,`Relative Influence`), y=`Relative Influence`)) +
  geom_bar(stat="identity") + 
  theme(axis.text.y = element_text(size=8,vjust = 0.8, hjust=1)) +
  labs(x=NULL,title = "Feature Importance from training data \n in the GBM for breast cancer",
       caption = "Note: Only top 20 features are shown for clear visualisation.")+
  coord_flip()

```


# Discussion 

<span style="background-color: yellow">XL comments: </span>

**Model wise:**

* `interaction.depth=1` (maximum depth of trees) suggests no potential interactions among selected features. Two implications:

    + Both PRS are independently predictive. (also based on the fact that both PRS got selected as important features)
    + No potential PRS interactions with other non-genetic predictors. 

* `n.trees` (Number of trees) increased from hundred to thousands now that we added more input features. This suggests more features require more complex model, which makes sense. 

**Results wise:** C-index is still very modest (0.01 improvement compared to initial exploration). Features selected by the model seem to be "dominated" by PRS based in the relative influence score.

* Interesting that some of the "unimportant" features from initial exploration (when searching 200+ features) showed up as important features this time (e.g. SBP, some ATC medication groups for hormone replacement, ATC medication group for type 2 diab). Perhaps the new added input features had an impact? 

* Same observation from initial exploration that a lot of blood biochemistry got selected by the model.

* People might wonder why some established RFs didn't get picked up by the model: 

    + Ethnicity: because our analysis population is genetic white ethnic group. 
    + Diabetes: in our list of important features, we got "A10BG" (indicator of taking medication for type 2 diabetes) and "Prevalent E11 Non-insulin-dependent diabetes mellitus status at baseline" (identified from HES).
    + Sex hormones & other hormones: "Testosterone", "SHBG" got selected as associated with BrCa but not sure if there are more hormones variables in our table.
    + Age at menopause (last menstrual period): Didn't get included as input feature because 43% missing; on the other hand, "Indicator of whether had menopause" did got included as input features but not associated with BrCa according to the model.  
    + Age of having children: "Age at last live birth" and "Age at first live birth" had missing data 31% so removed from input features. 
    + Inherited gene, X-rays and radiotherapy, Dense breast tissue, Benign breast disease, breastfeeding: UKB unavailable.
    + Previous cancer: We found the following cancer code associated with BrCa:

```{r}

test<-filter(importance,grepl('TEU_CaR',var))%>%
  filter(rel.inf!=0)%>%pull(var)

sapply(test, function(i) pretty_func(i))

```

   

# Model Visualisation

To help us understand what gbm is doing behind the scene, I drew some graph to reveal the **oversimplified** tree structures. Apparently it's not really straightforward to auto create a tree diagram from `gbm` output! 

```{r,fig.height=6}
img<-readPNG(file.path(config$explore, "GBM_structure.png"))
grid.raster(img,width=0.7,height=1)

```

Our optimal gbm model consists of `r optimal_combo2$optimal_trees[1]` trees and each tree would just be a stump (i.e. depth=`r optimal_combo$interaction.depth[1]`). The first 2 trees were roughly drew above (Note: It doesn't mean all trees start with 100k PRS! It just happens to be the case for first 2 trees). Final predictions of gbm are the weighted sum of predictions made by previous tree models. 



# Limitations & Next step

* `gbm` can only handle up to 1024 factor levels, we had to remove some input features beforehand to use `gbm` function.
* `gbm` doesn't have full list of tree-specific parameters. This change would require change in programming language, we would need to "imigrate" current work to Python, maybe not yet.











